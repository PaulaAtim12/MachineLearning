{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\paula\\anaconda3\\lib\\site-packages (1.3.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\paula\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in c:\\users\\paula\\anaconda3\\lib\\site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\paula\\anaconda3\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\paula\\anaconda3\\lib\\site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\paula\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn imbalanced-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "M7ayXkLXOtLW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "xJBUiI9WbiSE",
    "outputId": "6253d6ce-0426-4628-a6d5-89866a971605"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>customer</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>zipcodeOri</th>\n",
       "      <th>merchant</th>\n",
       "      <th>zipMerchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1093826151'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>4.55</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>'C352968107'</td>\n",
       "      <td>'2'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>39.68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>'C2054744914'</td>\n",
       "      <td>'4'</td>\n",
       "      <td>'F'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M1823072687'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>26.89</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>'C1760612790'</td>\n",
       "      <td>'3'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>17.25</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>'C757503768'</td>\n",
       "      <td>'5'</td>\n",
       "      <td>'M'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'M348934600'</td>\n",
       "      <td>'28007'</td>\n",
       "      <td>'es_transportation'</td>\n",
       "      <td>35.72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step       customer  age gender zipcodeOri       merchant zipMerchant  \\\n",
       "0     0  'C1093826151'  '4'    'M'    '28007'   'M348934600'     '28007'   \n",
       "1     0   'C352968107'  '2'    'M'    '28007'   'M348934600'     '28007'   \n",
       "2     0  'C2054744914'  '4'    'F'    '28007'  'M1823072687'     '28007'   \n",
       "3     0  'C1760612790'  '3'    'M'    '28007'   'M348934600'     '28007'   \n",
       "4     0   'C757503768'  '5'    'M'    '28007'   'M348934600'     '28007'   \n",
       "\n",
       "              category  amount  fraud  \n",
       "0  'es_transportation'    4.55      0  \n",
       "1  'es_transportation'   39.68      0  \n",
       "2  'es_transportation'   26.89      0  \n",
       "3  'es_transportation'   17.25      0  \n",
       "4  'es_transportation'   35.72      0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('bs140513_032310.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqCXpApwbq1b",
    "outputId": "db84ea61-f687-4a63-a6cd-e194a405694b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 594643 entries, 0 to 594642\n",
      "Data columns (total 10 columns):\n",
      " #   Column       Non-Null Count   Dtype  \n",
      "---  ------       --------------   -----  \n",
      " 0   step         594643 non-null  int64  \n",
      " 1   customer     594643 non-null  object \n",
      " 2   age          594643 non-null  object \n",
      " 3   gender       594643 non-null  object \n",
      " 4   zipcodeOri   594643 non-null  object \n",
      " 5   merchant     594643 non-null  object \n",
      " 6   zipMerchant  594643 non-null  object \n",
      " 7   category     594643 non-null  object \n",
      " 8   amount       594643 non-null  float64\n",
      " 9   fraud        594643 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(7)\n",
      "memory usage: 45.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info() #checking for any missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to do a count for the fraud column to see if the dataset is imbalanced. Yes, it is imbalanced. The non-fraud occurences is approximately 82 times bigger than fraudlent occurences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fraud   count\n",
      "0      0  587443\n",
      "1      1    7200\n"
     ]
    }
   ],
   "source": [
    "count_fraud = data.groupby('fraud').size().reset_index(name='count')\n",
    "print(count_fraud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into features and target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "G6q4_kWmbtp5"
   },
   "outputs": [],
   "source": [
    "X = data.drop('fraud', axis=1)\n",
    "y = data['fraud']   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the data into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uhJWQQwDcAlO"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HIyawqkEeSNu",
    "outputId": "510791fe-0bab-4aba-8f6b-a8224474da4b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37107     0\n",
       "163300    0\n",
       "108691    0\n",
       "429389    0\n",
       "222059    0\n",
       "Name: fraud, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the different types of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_cPcR_eadaFq"
   },
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data (scaling)\n",
    "numerical_features = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data (one-hot encoding)\n",
    "categorical_features = X.select_dtypes(include=['object']).columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Apply preprocessing to training data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform SMOTE to the imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the dataset is imbalanced, it has to be balanced. Oversampling and undersampling are the techniques to be used for balancing. \n",
    "\n",
    "(Ramentol, et al., 2012), describes undersampling as it entails deleting some of the data points connected to the overrepresented or dominating class in order to shrink the size of the original dataset, some of the undersampling techniques include, EasyEnsemble, BalanceCascade and MLPUS.\n",
    "Furthermore they explain, oversampling as simply the process of expanding the original dataset by replicating or reproducing some of the datapoints from the minority class. Techniques for oversampling include ADASYN, MWMOTE, RAMOBoost, and SMOTE.\n",
    "\n",
    "In this project, we choose oversampling because it preserves the information and better model generalization performance compared to undersampling. In particular we will perform SMOTE, (Chawla, et al., 2002), defines SMOTE as a technique that increases the representation of the minority class in order to alleviate class imbalance. SMOTE augments the minority class in the dataset by producing \"synthetic\" samples rather than just copying already-existing data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MncY02i3cF6F"
   },
   "outputs": [],
   "source": [
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X_train_preprocessed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform classification, train, test and evaluate the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to SMOTE, i decided to choose to try out two ensemble methods for classification, Random Forest Classifier and Gradient Boosting Classifier. \n",
    "\n",
    "(Dong, et al., 2020), states that by combining results from different voting mechanisms, ensemble learning techniques improve performance over that of any single constituent algorithm by utilizing multiple machine learning algorithms to generate weak predictive results based on features extracted through a diversity of projections on data.\n",
    "\n",
    "(www.turing.com, n.d.), describes that the classifier called Random Forest uses many decision trees on different dataset subsets and averages them to increase the dataset's projected accuracy. Random forests gather output from multiple decision trees and forecast the ultimate conclusion based on the majority vote of predictions, as opposed to depending solely on one decision tree.\n",
    "\n",
    "(PANCHOTIA, 2021), states that the combination of Gradient Descent and Boosting is called Gradient Boosting. Each new gradient boosting model uses the Gradient Descent Method to minimize the loss function from its predecessor. This process is repeated until a more accurate estimate of the target variable is obtained. In contrast to other ensemble techniques, gradient boosting builds a succession of trees in which each successive tree attempts to fix the errors of its predecessor.\n",
    "\n",
    "So as to decide whether to go for Random Forest (RF) or Gradient boosting (GB) techniques i had to run the code below for both and do the evaluation on the classification report. I noticed there was a major difference in the precison for 1, for RF precision was at 77% and for GB it was 26%, meaning Gradient Boosting was struggling in accurately predicting fraudlent tranactions as fraud, also making the f1-score to go low. This might be because it is more sensitive to outliers or the imbalanced data, thus leading to overfitting on test data. Random Forest Classifier might have performed better because it it handles outliers better, in addition, it's ensemble diversity, in that it builds multiple decision tress independently and combines them through voting thus making it robust to overfitting and improved generalization performance. The accuracies were quite close RF at 100% and GB at 97%, but you can see Random Forest performs better. THough accuracy is not our main focus.\n",
    "\n",
    "NOTE: THE WORKINGS ON THE GRADIENT BOOSTING IS BELOW, RANDOM FOREST CLASSIFIER THE MAIN PART FOLLOWS RIGHT AFTER."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[170309   5968]\n",
      " [    27   2089]]\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98    176277\n",
      "           1       0.26      0.99      0.41      2116\n",
      "\n",
      "    accuracy                           0.97    178393\n",
      "   macro avg       0.63      0.98      0.70    178393\n",
      "weighted avg       0.99      0.97      0.98    178393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier(random_state=42)\n",
    "gb_classifier.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Preprocess Testing Data\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Make predictions on testing data\n",
    "y_pred = gb_classifier.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate the performance\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OqyHpAGLepNE",
    "outputId": "9f4d9589-6a82-44a2-8816-1882ddaaf0e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[175716    561]\n",
      " [   279   1837]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    176277\n",
      "           1       0.77      0.87      0.81      2116\n",
      "\n",
      "    accuracy                           1.00    178393\n",
      "   macro avg       0.88      0.93      0.91    178393\n",
      "weighted avg       1.00      1.00      1.00    178393\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the Random Forest Classifier with class weights\n",
    "class_weights = {0: 1, 1: 5}\n",
    "model = RandomForestClassifier(class_weight=class_weights)\n",
    "\n",
    "# Train the model on the resampled data\n",
    "model.fit(X_resampled, y_resampled)\n",
    "\n",
    "# Apply preprocessing to testing data\n",
    "X_test_preprocessed = preprocessor.transform(X_test)\n",
    "\n",
    "# Predictions on the testing data\n",
    "y_pred = model.predict(X_test_preprocessed)\n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we decide to look at accuracy the system performed excellently at 100%. This might not be true to say it performed excellently by just looking at accuracy. We have to consider precision, recall and F1-score for 1, precision is how accurately a fraud 1 was categorized as fraudlent transaction 1, we can see 23% off from 100%, we can say the model tried because of imbalanced test data. Recall performed a bit better than precision meaning the model sensitivity is quite high. F1-score is harmonic mean of precision and recall. \n",
    "\n",
    "Finally, i can say that this proof-of-concept system performed well and can be implemented to the bank's system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Y. C. R. B. a. F. H. Enislay Ramentol, “SMOTE-RSB *: a hybrid preprocessing approach based on oversampling and undersampling for high imbalanced data-sets using SMOTE and rough sets theory,” Knowledge and Information Systems, vol. 33, pp. 245-265, 2012.\n",
    "\n",
    "N. V. Chawla, K. W. Bowyer, L. O. Hall and W. P. Kegelmeyer, “SMOTE: Syntehtic Minority Over\u0002sampling Technique,” Journal of Artificial Intelligence Researcxh, vol. 16, pp. 321-357, 2002. \n",
    "\n",
    "Dong, X., Yu, Z., Cao, W., Shi, Y. and Ma, Q., 2020. A survey on ensemble learning. Frontiers of Computer Science, 14, pp.241-258.\n",
    "\n",
    "www.turing.com. (n.d.). Random Forest Algorithm - How It Works and Why It Is So Effective. [online] Available at: https://www.turing.com/kb/random-forest-algorithm#what-is-random-forest-algorithm?.\n",
    "\n",
    "PANCHOTIA, R. (2021). Introduction To Gradient Boosting Classification. [online] Analytics Vidhya. Available at: https://medium.com/analytics-vidhya/introduction-to-gradient-boosting-classification-da4e81f54d3.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
